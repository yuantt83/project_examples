{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Convolutional Neural Network to Identify Spiral Arms\n",
    "Transfer Learning: use the EfficientNet Model. \n",
    "--\n",
    "Reference:\n",
    "Kalvankar et al. 2020\n",
    "https://ui.adsabs.harvard.edu/abs/2020arXiv200813611K\n",
    "\n",
    "We first try freezing all EfficientNet layers.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import efficientnet.keras as efn \n",
    "from efficientnet.keras import preprocess_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customised image sizes\n",
    "szx = 200\n",
    "szy = 200\n",
    "szz = 3\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training',\n",
    "                                                 target_size=(szx, szy),\n",
    "                                                 batch_size=32,\n",
    "                                                 subset='training',\n",
    "                                                 shuffle=False,\n",
    "                                                 class_mode='categorical')\n",
    "STEP_SIZE_TRAIN = training_set.n // training_set.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   validation_split=0.15)\n",
    "\n",
    "valid_set = valid_datagen.flow_from_directory('dataset/training',\n",
    "                                              target_size=(szx, szy),\n",
    "                                              batch_size=32,\n",
    "                                              subset='validation',\n",
    "                                              shuffle=False,\n",
    "                                              class_mode='categorical')\n",
    "STEP_SIZE_VALID = valid_set.n // valid_set.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the EfficientNet Model\n",
    "Keep the trainable parameters minimal at the  moment. If we open more layers for training, we need\n",
    "GPUs (e.g., SageMaker on AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "base_model = efn.EfficientNetB4(weights='imagenet', include_top=False, \n",
    "                                input_shape=(szx, szy, szz), pooling='avg')\n",
    "output = base_model.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "model_enet = Model(base_model.input, output)       \n",
    "\n",
    "model_enet.trainable = False\n",
    "for layer in model_enet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "import pandas as pd \n",
    "pd.set_option('max_colwidth', -1)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model_enet.layers]\n",
    "df_model_show = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Trainable or not'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all layers are indeed frozen\n",
    "df_model_show['Trainable or not'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_model_show.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_enet.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(model_enet)\n",
    "model.add(Dense(512, activation='relu', input_dim=model_enet.output_shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add visualisation to monitor the training and validation accuracy real-time:\n",
    "* code block below adapted from https://github.com/kapil-varshney/utilities/blob/master/training_plot/training_plot_ex_with_cifar10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPlot(keras.callbacks.Callback):\n",
    "    \n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses and accuracies\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        # Append the logs, losses and accuracies to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        \n",
    "        # Before plotting ensure at least 2 epochs have passed\n",
    "        if len(self.losses) > 1:\n",
    "            \n",
    "            # Clear the previous plot\n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            \n",
    "            # You can chose the style of your preference\n",
    "            # print(plt.style.available) to see the available options\n",
    "            plt.style.use(\"seaborn-talk\")\n",
    "            \n",
    "            # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.losses, linestyle=':', label = \"train_loss\")\n",
    "            plt.plot(N, self.acc, linestyle=':', label = \"train_accuracy\")\n",
    "            plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "            plt.plot(N, self.val_acc, label = \"val_accuracy\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(epoch))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "plot_losses = TrainingPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='/Users/tiantianyuan/work/learn_py/self/astro/dataset/wts_enet4_model_freeze.h5', verbose=2, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=4)\n",
    "\n",
    "csv_logger = CSVLogger('/Users/tiantianyuan/work/learn_py/self/astro/dataset/wts_enet4_model_freeze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "results = model.fit(training_set,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10,\n",
    "                    callbacks=[plot_losses, checkpointer, early_stopping, reduce_lr, csv_logger])\n",
    "t2 = time.time()\n",
    "print('Model running time is {:.2f}mins'.format((t2 - t1)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "# !mkdir -p saved_model\n",
    "model_enet.save('saved_model/enet4_model_freeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enet.save('saved_model/enet4_model_freeze.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation using Confusion Matrix and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model,load_model\n",
    "model_check = load_model('saved_model/enet4_model_freeze.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test',\n",
    "                                            target_size=(szx, szy),\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False,\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "test_set.reset()\n",
    "\n",
    "Y_pred = model_check.predict(\n",
    "                            test_set,\n",
    "                            steps=test_set.n / test_set.batch_size,\n",
    "                            verbose=1)\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_set.classes, y_pred)\n",
    "\n",
    "print('The confusion matrix is \\n{}\\n'.format(cm))\n",
    "\n",
    "f1 = classification_report(test_set.classes, y_pred, target_names=training_set.class_indices)\n",
    "print('F1 score is {}\\n'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
