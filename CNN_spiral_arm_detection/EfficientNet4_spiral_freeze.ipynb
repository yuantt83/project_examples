{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Convolutional Neural Network to Identify Spiral Arms\n",
    "Transfer Learning: use the EfficientNet Model. \n",
    "--\n",
    "Reference:\n",
    "Kalvankar et al. 2020\n",
    "https://ui.adsabs.harvard.edu/abs/2020arXiv200813611K\n",
    "\n",
    "We first try freezing all EfficientNet layers.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import efficientnet.keras as efn \n",
    "from efficientnet.keras import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31848 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# customised image sizes\n",
    "szx = 200\n",
    "szy = 200\n",
    "szz = 3\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training',\n",
    "                                                 target_size=(szx, szy),\n",
    "                                                 batch_size=32,\n",
    "                                                 subset='training',\n",
    "                                                 shuffle=False,\n",
    "                                                 class_mode='categorical')\n",
    "STEP_SIZE_TRAIN = training_set.n // training_set.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4776 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   validation_split=0.15)\n",
    "\n",
    "valid_set = valid_datagen.flow_from_directory('dataset/training',\n",
    "                                              target_size=(szx, szy),\n",
    "                                              batch_size=32,\n",
    "                                              subset='validation',\n",
    "                                              shuffle=False,\n",
    "                                              class_mode='categorical')\n",
    "STEP_SIZE_VALID = valid_set.n // valid_set.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the EfficientNet Model\n",
    "Keep the trainable parameters minimal at the  moment. If we open more layers for training, we need\n",
    "GPUs (e.g., SageMaker on AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "base_model = efn.EfficientNetB4(weights='imagenet', include_top=False, \n",
    "                                input_shape=(szx, szy, szz), pooling='avg')\n",
    "output = base_model.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "model_enet = Model(base_model.input, output)       \n",
    "\n",
    "model_enet.trainable = False\n",
    "for layer in model_enet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "import pandas as pd \n",
    "pd.set_option('max_colwidth', None)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model_enet.layers]\n",
    "df_model_show = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Trainable or not'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       469\n",
       "unique        1\n",
       "top       False\n",
       "freq        469\n",
       "Name: Trainable or not, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all layers are indeed frozen\n",
    "df_model_show['Trainable or not'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Trainable or not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b09d970&gt;</td>\n",
       "      <td>block7b_expand_conv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48a77f2b0&gt;</td>\n",
       "      <td>block7b_expand_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x7ff48b09dd90&gt;</td>\n",
       "      <td>block7b_expand_activation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7ff48a2c1520&gt;</td>\n",
       "      <td>block7b_dwconv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48b09de50&gt;</td>\n",
       "      <td>block7b_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x7ff48b0aa910&gt;</td>\n",
       "      <td>block7b_activation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7ff48b0b5ac0&gt;</td>\n",
       "      <td>block7b_se_squeeze</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Reshape object at 0x7ff482ec1850&gt;</td>\n",
       "      <td>block7b_se_reshape</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b0aa370&gt;</td>\n",
       "      <td>block7b_se_reduce</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b0a3b50&gt;</td>\n",
       "      <td>block7b_se_expand</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Multiply object at 0x7ff48b0b5880&gt;</td>\n",
       "      <td>block7b_se_excite</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48a77fc70&gt;</td>\n",
       "      <td>block7b_project_conv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48b0aa400&gt;</td>\n",
       "      <td>block7b_project_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>&lt;efficientnet.model.get_dropout.&lt;locals&gt;.FixedDropout object at 0x7ff48b55dd90&gt;</td>\n",
       "      <td>block7b_drop</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add object at 0x7ff48a76c100&gt;</td>\n",
       "      <td>block7b_add</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b0944c0&gt;</td>\n",
       "      <td>top_conv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48b565610&gt;</td>\n",
       "      <td>top_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Activation object at 0x7ff48b565ac0&gt;</td>\n",
       "      <td>top_activation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7ff48b56c4c0&gt;</td>\n",
       "      <td>avg_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.core.Flatten object at 0x7ff482f99f40&gt;</td>\n",
       "      <td>flatten_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Layer Type  \\\n",
       "449                 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b09d970>   \n",
       "450  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48a77f2b0>   \n",
       "451                      <tensorflow.python.keras.layers.core.Activation object at 0x7ff48b09dd90>   \n",
       "452        <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7ff48a2c1520>   \n",
       "453  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48b09de50>   \n",
       "454                      <tensorflow.python.keras.layers.core.Activation object at 0x7ff48b0aa910>   \n",
       "455       <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7ff48b0b5ac0>   \n",
       "456                         <tensorflow.python.keras.layers.core.Reshape object at 0x7ff482ec1850>   \n",
       "457                 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b0aa370>   \n",
       "458                 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b0a3b50>   \n",
       "459                       <tensorflow.python.keras.layers.merge.Multiply object at 0x7ff48b0b5880>   \n",
       "460                 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48a77fc70>   \n",
       "461  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48b0aa400>   \n",
       "462                <efficientnet.model.get_dropout.<locals>.FixedDropout object at 0x7ff48b55dd90>   \n",
       "463                            <tensorflow.python.keras.layers.merge.Add object at 0x7ff48a76c100>   \n",
       "464                 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ff48b0944c0>   \n",
       "465  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7ff48b565610>   \n",
       "466                      <tensorflow.python.keras.layers.core.Activation object at 0x7ff48b565ac0>   \n",
       "467       <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7ff48b56c4c0>   \n",
       "468                         <tensorflow.python.keras.layers.core.Flatten object at 0x7ff482f99f40>   \n",
       "\n",
       "                    Layer Name  Trainable or not  \n",
       "449        block7b_expand_conv             False  \n",
       "450          block7b_expand_bn             False  \n",
       "451  block7b_expand_activation             False  \n",
       "452             block7b_dwconv             False  \n",
       "453                 block7b_bn             False  \n",
       "454         block7b_activation             False  \n",
       "455         block7b_se_squeeze             False  \n",
       "456         block7b_se_reshape             False  \n",
       "457          block7b_se_reduce             False  \n",
       "458          block7b_se_expand             False  \n",
       "459          block7b_se_excite             False  \n",
       "460       block7b_project_conv             False  \n",
       "461         block7b_project_bn             False  \n",
       "462               block7b_drop             False  \n",
       "463                block7b_add             False  \n",
       "464                   top_conv             False  \n",
       "465                     top_bn             False  \n",
       "466             top_activation             False  \n",
       "467                   avg_pool             False  \n",
       "468                  flatten_1             False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_model_show.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1792)\n"
     ]
    }
   ],
   "source": [
    "print(model_enet.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Functional)         (None, 1792)              17673816  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               918016    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 18,856,027\n",
      "Trainable params: 1,182,211\n",
      "Non-trainable params: 17,673,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(model_enet)\n",
    "model.add(Dense(512, activation='relu', input_dim=model_enet.output_shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add visualisation to monitor the training and validation accuracy real-time:\n",
    "* code block below adapted from https://github.com/kapil-varshney/utilities/blob/master/training_plot/training_plot_ex_with_cifar10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPlot(keras.callbacks.Callback):\n",
    "    \n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses and accuracies\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        # Append the logs, losses and accuracies to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        \n",
    "        # Before plotting ensure at least 2 epochs have passed\n",
    "        if len(self.losses) > 1:\n",
    "            \n",
    "            # Clear the previous plot\n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            \n",
    "            # You can chose the style of your preference\n",
    "            # print(plt.style.available) to see the available options\n",
    "            plt.style.use(\"seaborn-talk\")\n",
    "            \n",
    "            # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.losses, linestyle=':', label = \"train_loss\")\n",
    "            plt.plot(N, self.acc, linestyle=':', label = \"train_accuracy\")\n",
    "            plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "            plt.plot(N, self.val_acc, label = \"val_accuracy\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(epoch))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "plot_losses = TrainingPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='/Users/tiantianyuan/work/learn_py/self/astro/dataset/wts_enet4_model_freeze.h5', verbose=2, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=4)\n",
    "\n",
    "csv_logger = CSVLogger('/Users/tiantianyuan/work/learn_py/self/astro/dataset/wts_enet4_model_freeze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "results = model.fit(training_set,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10,\n",
    "                    callbacks=[plot_losses, checkpointer, early_stopping, reduce_lr, csv_logger])\n",
    "t2 = time.time()\n",
    "print('Model running time is {:.2f}mins'.format((t2 - t1)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "# !mkdir -p saved_model\n",
    "model_enet.save('saved_model/enet4_model_freeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enet.save('saved_model/enet4_model_freeze.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation using Confusion Matrix and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model,load_model\n",
    "model_check = load_model('saved_model/enet4_model_freeze.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test',\n",
    "                                            target_size=(szx, szy),\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False,\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "test_set.reset()\n",
    "\n",
    "Y_pred = model_check.predict(\n",
    "                            test_set,\n",
    "                            steps=test_set.n / test_set.batch_size,\n",
    "                            verbose=1)\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_set.classes, y_pred)\n",
    "\n",
    "print('The confusion matrix is \\n{}\\n'.format(cm))\n",
    "\n",
    "f1 = classification_report(test_set.classes, y_pred, target_names=training_set.class_indices)\n",
    "print('F1 score is {}\\n'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
